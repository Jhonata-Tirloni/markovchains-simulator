# markovchains-simulator
A Markov chains simulator and basic lookup. 
